import streamlit as st
from pypdf import PdfReader
from sentence_transformers import SentenceTransformer
import chromadb
from chromadb.config import Settings
import numpy as np
import os
import json
import uuid

# ---------------- Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù†Ø¸Ø§Ù… ----------------
EMBED_MODEL = SentenceTransformer("all-MiniLM-L6-v2")
DATA_DIR = "data"
MEMORY_DIR = "memory"
os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(MEMORY_DIR, exist_ok=True)
DB_DIR = "chroma_db"

client = chromadb.Client(Settings(persist_directory=DB_DIR))
try:
    collection = client.get_collection("curriculum")
except:
    collection = client.create_collection("curriculum")

# ---------------- ÙˆØ§Ø¬Ù‡Ø© Streamlit ----------------
st.set_page_config(page_title="Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ù…Ù†Ù‡Ø§Ø¬ Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠ", layout="wide")
st.title("ğŸ“˜ Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ù…Ù†Ù‡Ø§Ø¬ Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠ")
st.write("Ù…Ø±Ø­Ø¨Ù‹Ø§ ğŸ‘‹ Ù‡Ø°Ø§ Ø§Ù„Ù†Ø¸Ø§Ù… ÙŠØ¬ÙŠØ¨ ÙÙ‚Ø· Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªÙŠ Ø£Ø¶ÙØªÙ‡Ø§ Ø£Ù†Øª (Ø§Ù„Ù…Ø¹Ù„Ù…).")

mode = st.sidebar.selectbox("Ø§Ø®ØªØ± Ø§Ù„ÙˆØ¶Ø¹:", ["ğŸ‘¨â€ğŸ« ÙˆØ¶Ø¹ Ø§Ù„Ù…Ø¹Ù„Ù…", "ğŸ“ ÙˆØ¶Ø¹ Ø§Ù„Ø·Ø§Ù„Ø¨"])

# ---------------- ÙˆØ¶Ø¹ Ø§Ù„Ù…Ø¹Ù„Ù… ----------------
if mode == "ğŸ‘¨â€ğŸ« ÙˆØ¶Ø¹ Ø§Ù„Ù…Ø¹Ù„Ù…":
    st.header("ğŸ‘¨â€ğŸ« Ø±ÙØ¹ Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ù†Ù‡Ø§Ø¬")
    uploaded_files = st.file_uploader("Ø§Ø±ÙØ¹ Ù…Ù„ÙØ§Øª PDF Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø§Ù„Ù…Ù†Ù‡Ø§Ø¬:", type=["pdf"], accept_multiple_files=True)
    if uploaded_files:
        for file in uploaded_files:
            reader = PdfReader(file)
            text = ""
            for page in reader.pages:
                text += page.extract_text() + "\n"

            # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø£Ø¬Ø²Ø§Ø¡ ØµØºÙŠØ±Ø©
            words = text.split()
            chunk_size = 300
            overlap = 50
            chunks = []
            i = 0
            idx = 0
            while i < len(words):
                chunk = " ".join(words[i:i+chunk_size])
                chunks.append(chunk)
                i += chunk_size - overlap

            # Ø¥Ù†Ø´Ø§Ø¡ embeddings
            embs = EMBED_MODEL.encode(chunks)
            ids = [str(uuid.uuid4()) for _ in chunks]
            metas = [{"file": file.name} for _ in chunks]
            collection.add(documents=chunks, embeddings=embs.tolist(), metadatas=metas, ids=ids)

        client.persist()
        st.success("âœ… ØªÙ… Ø±ÙØ¹ ÙˆÙÙ‡Ø±Ø³Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø¨Ù†Ø¬Ø§Ø­!")

# ---------------- ÙˆØ¶Ø¹ Ø§Ù„Ø·Ø§Ù„Ø¨ ----------------
else:
    st.header("ğŸ“ Ø§Ø³Ø£Ù„ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ")
    question = st.text_input("Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§:")

    if st.button("Ø§Ø³Ø£Ù„"):
        if not question.strip():
            st.warning("â— Ø§Ù„Ø±Ø¬Ø§Ø¡ ÙƒØªØ§Ø¨Ø© Ø³Ø¤Ø§Ù„ Ø£ÙˆÙ„Ø§Ù‹.")
        else:
            q_emb = EMBED_MODEL.encode([question])
            results = collection.query(query_embeddings=q_emb.tolist(), n_results=3)
            docs = results["documents"][0]
            metas = results["metadatas"][0]

            if len(docs) == 0:
                st.warning("ğŸš« Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙƒØ§ÙÙŠØ© ÙÙŠ Ø§Ù„Ù…Ù†Ù‡Ø§Ø¬ Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù† Ù‡Ø°Ø§ Ø§Ù„Ø³Ø¤Ø§Ù„.")
            else:
                st.subheader("ğŸ“– Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ù…Ù† Ø§Ù„Ù…Ù†Ù‡Ø§Ø¬:")
                for doc, meta in zip(docs, metas):
                    st.markdown(f"**Ù…Ù† Ø§Ù„Ù…Ù„Ù:** {meta['file']}")
                    st.write(doc)
                    st.markdown("---")

                # Ø­ÙØ¸ Ø§Ù„Ø³Ø¤Ø§Ù„ ÙÙŠ Ø°Ø§ÙƒØ±Ø© Ø§Ù„ØªØ¹Ù„Ù…
                memory_file = os.path.join(MEMORY_DIR, f"{uuid.uuid4()}.json")
                with open(memory_file, "w", encoding="utf-8") as f:
                    json.dump({"question": question, "answers": docs}, f, ensure_ascii=False)
                st.success("âœ… ØªÙ… Ø­ÙØ¸ Ù‡Ø°Ø§ Ø§Ù„Ø³Ø¤Ø§Ù„ Ù„Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠ.")
